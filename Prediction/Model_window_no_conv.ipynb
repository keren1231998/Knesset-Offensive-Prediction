{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0bf85b-47b3-4103-8535-ef88b86a3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3745157/4248719676.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('from IPython.core.display import clear_output');\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "    <script>\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('from IPython.core.display import clear_output');\n",
    "    </script>\n",
    "\"\"\"))\n",
    "\n",
    "import IPython\n",
    "IPython.get_ipython().config.TerminalInteractiveShell.rate_limit_window = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bf563c-a6d9-4348-9a1b-974092420a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>committee_name</th>\n",
       "      <th>session_id</th>\n",
       "      <th>chairperson</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>conversation</th>\n",
       "      <th>contain_offensive_words</th>\n",
       "      <th>dicta_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>. אני כן אסתום לך את הפה.. .</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>יצחק כהן</td>\n",
       "      <td>. לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>רוחמה אברהם</td>\n",
       "      <td>. אם חברה הולכת להפרטה, אסור לה לפרסם תשקיף..</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>. אני קורא אותך לסדר..</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>יצחק כהן</td>\n",
       "      <td>. לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127835</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>קריאות</td>\n",
       "      <td>\\n- - -\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127836</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>גלעד קריב</td>\n",
       "      <td>\\nמין שאינו במינו.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127837</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>\\nההערה הזאת צרמה לי מאוד באוזן על המישור המקצ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127838</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>אלעזר שטרן</td>\n",
       "      <td>\\nאדוני, אני אשמח להגיב לדבר הזה. קודם כול, אנ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127839</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>\\nמועצה דתית היא לא גוף ספציפי?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127840 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              committee_name  session_id    chairperson    speaker_name  \\\n",
       "0                      אל על       64670  אברהם הירשזון   אברהם הירשזון   \n",
       "1                      אל על       64670  אברהם הירשזון        יצחק כהן   \n",
       "2                      אל על       64670  אברהם הירשזון     רוחמה אברהם   \n",
       "3                      אל על       64670  אברהם הירשזון   אברהם הירשזון   \n",
       "4                      אל על       64670  אברהם הירשזון        יצחק כהן   \n",
       "...                      ...         ...            ...             ...   \n",
       "127835  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן          קריאות   \n",
       "127836  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן       גלעד קריב   \n",
       "127837  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      שמחה רוטמן   \n",
       "127838  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      אלעזר שטרן   \n",
       "127839  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      שמחה רוטמן   \n",
       "\n",
       "                                             conversation  \\\n",
       "0                           . אני כן אסתום לך את הפה.. .    \n",
       "1       . לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...   \n",
       "2          . אם חברה הולכת להפרטה, אסור לה לפרסם תשקיף..    \n",
       "3                                 . אני קורא אותך לסדר..    \n",
       "4       . לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...   \n",
       "...                                                   ...   \n",
       "127835                                          \\n- - -\\n   \n",
       "127836                               \\nמין שאינו במינו.\\n   \n",
       "127837  \\nההערה הזאת צרמה לי מאוד באוזן על המישור המקצ...   \n",
       "127838  \\nאדוני, אני אשמח להגיב לדבר הזה. קודם כול, אנ...   \n",
       "127839                  \\nמועצה דתית היא לא גוף ספציפי?\\n   \n",
       "\n",
       "        contain_offensive_words  dicta_answer  \n",
       "0                             0           0.0  \n",
       "1                             0           0.0  \n",
       "2                             0           0.0  \n",
       "3                             1           1.0  \n",
       "4                             0           0.0  \n",
       "...                         ...           ...  \n",
       "127835                        0           0.0  \n",
       "127836                        0           0.0  \n",
       "127837                        0           0.0  \n",
       "127838                        0           0.0  \n",
       "127839                        0           0.0  \n",
       "\n",
       "[127840 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"pred_data_preprocessed.csv\")\n",
    "df = df.drop(\"position\",axis=1)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27eafd5-5f77-4886-90b3-e54f0b5d9b60",
   "metadata": {},
   "source": [
    "## Model with Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a8b8a0-744d-43ad-a89b-8ec71faac83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:54:53,822 - INFO - Starting training process...\n",
      "2025-02-05 14:54:53,822 - INFO - Loaded dataset with 127840 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:54:55,488 - INFO - Created windowed datasets:\n",
      "2025-02-05 14:54:55,489 - INFO - Training windows: 96016\n",
      "2025-02-05 14:54:55,489 - INFO - Validation windows: 11473\n",
      "2025-02-05 14:54:55,490 - INFO - Test windows: 15758\n",
      "2025-02-05 14:54:55,599 - INFO - Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|██████████| 3001/3001 [03:28<00:00, 14.40it/s, train_loss=0.3118]\n",
      "Epoch 1/5 [Validation]: 100%|██████████| 180/180 [00:29<00:00,  6.04it/s, val_loss=0.0338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:59:00,025 - INFO - Epoch 1: Train Loss = 0.3765, Val Loss = 0.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|██████████| 3001/3001 [03:30<00:00, 14.23it/s, train_loss=0.5271]\n",
      "Epoch 2/5 [Validation]: 100%|██████████| 180/180 [00:29<00:00,  6.04it/s, val_loss=0.0366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:03:09,399 - INFO - Epoch 2: Train Loss = 0.3151, Val Loss = 0.2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|██████████| 3001/3001 [03:30<00:00, 14.25it/s, train_loss=0.5240]\n",
      "Epoch 3/5 [Validation]: 100%|██████████| 180/180 [00:29<00:00,  6.06it/s, val_loss=0.0159]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:07:09,688 - INFO - Epoch 3: Train Loss = 0.3016, Val Loss = 0.2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5 [Train]: 100%|██████████| 3001/3001 [03:31<00:00, 14.21it/s, train_loss=0.1497]\n",
      "Epoch 4/5 [Validation]: 100%|██████████| 180/180 [00:29<00:00,  6.05it/s, val_loss=0.0144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:11:10,617 - INFO - Epoch 4: Train Loss = 0.2878, Val Loss = 0.2673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5 [Train]: 100%|██████████| 3001/3001 [03:31<00:00, 14.22it/s, train_loss=0.0621]\n",
      "Epoch 5/5 [Validation]: 100%|██████████| 180/180 [00:29<00:00,  6.05it/s, val_loss=0.0097]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:15:11,414 - INFO - Early stopping triggered after epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3745157/3801445510.py:532: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:15:39,116 - INFO - Loaded best model from epoch 2\n",
      "2025-02-05 15:15:39,116 - INFO - \n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation set: 100%|██████████| 180/180 [00:29<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:16:14,082 - INFO - \n",
      "Validation Metrics:\n",
      "2025-02-05 15:16:14,083 - INFO - Accuracy: 0.8965\n",
      "2025-02-05 15:16:14,083 - INFO - Precision: 0.8875\n",
      "2025-02-05 15:16:14,083 - INFO - Recall: 0.8965\n",
      "2025-02-05 15:16:14,084 - INFO - F1 Score: 0.8805\n",
      "2025-02-05 15:16:14,084 - INFO - ROC AUC: 0.8831\n",
      "2025-02-05 15:16:14,084 - INFO - \n",
      "Per-session metrics:\n",
      "2025-02-05 15:16:14,084 - INFO - Mean accuracy: 0.8965\n",
      "2025-02-05 15:16:14,085 - INFO - Std accuracy: 0.3047\n",
      "2025-02-05 15:16:14,098 - INFO - \n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████| 247/247 [00:40<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:17:01,958 - INFO - \n",
      "Test Metrics:\n",
      "2025-02-05 15:17:01,959 - INFO - Accuracy: 0.8471\n",
      "2025-02-05 15:17:01,960 - INFO - Precision: 0.8370\n",
      "2025-02-05 15:17:01,960 - INFO - Recall: 0.8471\n",
      "2025-02-05 15:17:01,960 - INFO - F1 Score: 0.8282\n",
      "2025-02-05 15:17:01,961 - INFO - ROC AUC: 0.8704\n",
      "2025-02-05 15:17:01,961 - INFO - \n",
      "Per-session metrics:\n",
      "2025-02-05 15:17:01,961 - INFO - Mean accuracy: 0.8471\n",
      "2025-02-05 15:17:01,961 - INFO - Std accuracy: 0.3599\n",
      "2025-02-05 15:17:04,059 - INFO - \n",
      "Training and evaluation completed!\n",
      "2025-02-05 15:17:04,059 - INFO - Model saved to: results_windowed/run_20250205_145453/models/final_model\n",
      "2025-02-05 15:17:04,060 - INFO - Tokenizer saved to: results_windowed/run_20250205_145453/models/tokenizer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import torch.amp\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class WindowDictaDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.windows = []\n",
    "        self.labels = []\n",
    "        self.session_ids = []\n",
    "        \n",
    "        # Group by session\n",
    "        grouped = df.groupby('session_id')\n",
    "        for session_id, session_df in grouped:\n",
    "            session_convs = session_df['conversation'].tolist()\n",
    "            session_labels = session_df['dicta_answer'].tolist()\n",
    "            \n",
    "            # Create windows of size 3 and predict the 4th (without seeing it)\n",
    "            for i in range(0, len(session_convs) - 3):\n",
    "                # Only use previous 3 conversations with their labels\n",
    "                window = [\n",
    "                    f\"{session_convs[i]} [LABEL] {session_labels[i]}\",\n",
    "                    f\"{session_convs[i+1]} [LABEL] {session_labels[i+1]}\",\n",
    "                    f\"{session_convs[i+2]} [LABEL] {session_labels[i+2]}\"\n",
    "                ]\n",
    "                # The label to predict (4th conversation's label)\n",
    "                label = session_labels[i+3]\n",
    "                self.windows.append(window)\n",
    "                self.labels.append(label)\n",
    "                self.session_ids.append(session_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Concatenate only the three previous conversations\n",
    "        concatenated_text = \" [SEP] \".join(window)\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            concatenated_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(int(label), dtype=torch.long),\n",
    "            'session_id': self.session_ids[idx]\n",
    "        }\n",
    "        \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def setup_logging(base_dir='results_windowed'):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    results_dir = os.path.join(base_dir, f'run_{timestamp}')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    log_file = os.path.join(results_dir, 'training.log')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    models_dir = os.path.join(results_dir, 'models')\n",
    "    metrics_dir = os.path.join(results_dir, 'metrics')\n",
    "    \n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "    \n",
    "    return results_dir, plots_dir, models_dir, metrics_dir\n",
    "\n",
    "def prepare_windowed_data(df):\n",
    "    \"\"\"Prepare the data by ensuring proper session handling and creating train/val/test splits\"\"\"\n",
    "    # Get unique session IDs\n",
    "    session_ids = df['session_id'].unique()\n",
    "    \n",
    "    # Split sessions into train/val/test\n",
    "    train_sessions, temp_sessions = train_test_split(\n",
    "        session_ids, test_size=0.2, random_state=42\n",
    "    )\n",
    "    val_sessions, test_sessions = train_test_split(\n",
    "        temp_sessions, test_size=0.5, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create dataframes for each split\n",
    "    train_df = df[df['session_id'].isin(train_sessions)]\n",
    "    val_df = df[df['session_id'].isin(val_sessions)]\n",
    "    test_df = df[df['session_id'].isin(test_sessions)]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def evaluate_model(model, dataloader, device, plots_dir=None, phase='test'):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    actual_labels = []\n",
    "    session_predictions = {}  # Track predictions by session\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f'Evaluating {phase} set'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            session_ids = batch['session_id']\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get probabilities and predictions\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            probabilities.extend(probs[:, 1].cpu().tolist())  # Probability of positive class\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "            \n",
    "            # Track predictions by session\n",
    "            for sid, pred, actual, prob in zip(session_ids, preds.cpu().tolist(), labels.cpu().tolist(), probs[:, 1].cpu().tolist()):\n",
    "                if sid not in session_predictions:\n",
    "                    session_predictions[sid] = {'pred': [], 'actual': [], 'prob': []}\n",
    "                session_predictions[sid]['pred'].append(pred)\n",
    "                session_predictions[sid]['actual'].append(actual)\n",
    "                session_predictions[sid]['prob'].append(prob)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    metrics = calculate_metrics(actual_labels, predictions, probabilities, session_predictions)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    if plots_dir:\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                            os.path.join(plots_dir, f'confusion_matrix_{phase}.png'))\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(actual_labels, probabilities, \n",
    "                     os.path.join(plots_dir, f'roc_curve_{phase}.png'))\n",
    "        \n",
    "        # Plot session performance\n",
    "        plot_session_performance(session_predictions, \n",
    "                               os.path.join(plots_dir, f'session_performance_{phase}.png'))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(actual_labels, predictions, probabilities, session_predictions):\n",
    "    \"\"\"Calculate comprehensive metrics including per-session analysis and ROC AUC\"\"\"\n",
    "    # Overall metrics\n",
    "    accuracy = float(accuracy_score(actual_labels, predictions))\n",
    "    precision = float(precision_score(actual_labels, predictions, average='weighted'))\n",
    "    recall = float(recall_score(actual_labels, predictions, average='weighted'))\n",
    "    f1 = float(f1_score(actual_labels, predictions, average='weighted'))\n",
    "    cm = confusion_matrix(actual_labels, predictions).tolist()  # Convert to list\n",
    "    \n",
    "    # ROC AUC\n",
    "    try:\n",
    "        roc_auc = float(roc_auc_score(actual_labels, probabilities))\n",
    "    except ValueError:\n",
    "        # This can happen if there's only one class in y_true\n",
    "        roc_auc = None\n",
    "    \n",
    "    # Per-session metrics\n",
    "    session_accuracies = []\n",
    "    for session in session_predictions.values():\n",
    "        if session['actual']:  # Check if session has predictions\n",
    "            session_acc = float(accuracy_score(session['actual'], session['pred']))\n",
    "            session_accuracies.append(session_acc)\n",
    "    \n",
    "    # Convert numpy types to Python native types\n",
    "    session_metrics = {\n",
    "        'mean_accuracy': float(np.mean(session_accuracies)),\n",
    "        'std_accuracy': float(np.std(session_accuracies)),\n",
    "        'min_accuracy': float(np.min(session_accuracies)),\n",
    "        'max_accuracy': float(np.max(session_accuracies))\n",
    "    }\n",
    "    \n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': classification_report(actual_labels, predictions),\n",
    "        'session_metrics': session_metrics\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_roc_curve(actual_labels, probabilities, save_path):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(actual_labels, probabilities)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not plot ROC curve: {e}\")\n",
    "        \n",
    "def plot_confusion_matrix(cm, save_path):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_session_performance(session_predictions, save_path):\n",
    "    \"\"\"Plot distribution of per-session accuracies\"\"\"\n",
    "    accuracies = []\n",
    "    for session in session_predictions.values():\n",
    "        if session['actual']:  # Check if session has predictions\n",
    "            acc = accuracy_score(session['actual'], session['pred'])\n",
    "            accuracies.append(acc)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(accuracies, bins=20, edgecolor='black')\n",
    "    plt.title('Distribution of Session Accuracies')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Number of Sessions')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def train_model(train_dataloader, val_dataloader, model, optimizer, device, \n",
    "                num_epochs=3, results_dir=None, gradient_accumulation_steps=4):\n",
    "    model.train()\n",
    "    training_stats = []\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "    scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else torch.amp.GradScaler('cpu')\n",
    "    \n",
    "    # Create scheduler with warmup\n",
    "    num_training_steps = len(train_dataloader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 10\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps, \n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Only use autocast when CUDA is available\n",
    "            if torch.cuda.is_available():\n",
    "                with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    loss = outputs.loss / gradient_accumulation_steps\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss / gradient_accumulation_steps\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * gradient_accumulation_steps\n",
    "            progress_bar.set_postfix({'train_loss': f'{loss.item() * gradient_accumulation_steps:.4f}'})\n",
    "\n",
    "        # Validation phase with tqdm\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} [Validation]')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_progress_bar:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                batch_val_loss = outputs.loss.item()\n",
    "                val_loss += batch_val_loss\n",
    "                \n",
    "                # Update validation progress bar with current loss\n",
    "                val_progress_bar.set_postfix({'val_loss': f'{batch_val_loss:.4f}'})\n",
    "        \n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "        \n",
    "        # Save stats\n",
    "        epoch_stats = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': total_loss / len(train_dataloader),\n",
    "            'val_loss': val_loss\n",
    "        }\n",
    "        training_stats.append(epoch_stats)\n",
    "        \n",
    "        # Save checkpoint if it's the best model\n",
    "        if epoch == 0 or val_loss < min(s['val_loss'] for s in training_stats[:-1]):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, os.path.join(results_dir, 'models', 'best_model.pt'))\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(f'Early stopping triggered after epoch {epoch + 1}')\n",
    "            break\n",
    "        \n",
    "        logging.info(f'Epoch {epoch + 1}: Train Loss = {epoch_stats[\"train_loss\"]:.4f}, '\n",
    "                    f'Val Loss = {epoch_stats[\"val_loss\"]:.4f}')\n",
    "    \n",
    "    return training_stats\n",
    "\n",
    "def predict_next_conversation(model, tokenizer, previous_three_conversations, device):\n",
    "    \"\"\"Predict the label for the next conversation based on the previous three conversations\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    concatenated_text = \" [SEP] \".join(previous_three_conversations)\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "        concatenated_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "    \n",
    "    return preds.item()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main training pipeline for the windowed conversation classification model\n",
    "    \"\"\"\n",
    "    # Setup logging and directories\n",
    "    results_dir, plots_dir, models_dir, metrics_dir = setup_logging()\n",
    "    logging.info(\"Starting training process...\")\n",
    "    \n",
    "    # Load your data (IMPORTANT: Uncomment and modify to load your actual dataset)\n",
    "    # df = pd.read_csv('your_conversation_data.csv')\n",
    "    # Ensure your DataFrame has these columns:\n",
    "    # - 'session_id': Unique identifier for conversation sessions\n",
    "    # - 'conversation': The text of each conversation turn\n",
    "    # - 'dicta_answer': Binary label (0 or 1) for classification\n",
    "    \n",
    "   \n",
    "    logging.info(f\"Loaded dataset with {len(df)} samples\")\n",
    "    \n",
    "    # Prepare windowed data\n",
    "    train_df, val_df, test_df = prepare_windowed_data(df)\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-multilingual-cased',\n",
    "        num_labels=2  # Binary classification\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = WindowDictaDataset(train_df, tokenizer)\n",
    "    val_dataset = WindowDictaDataset(val_df, tokenizer)\n",
    "    test_dataset = WindowDictaDataset(test_df, tokenizer)\n",
    "    \n",
    "    logging.info(f\"Created windowed datasets:\")\n",
    "    logging.info(f\"Training windows: {len(train_dataset)}\")\n",
    "    logging.info(f\"Validation windows: {len(val_dataset)}\")\n",
    "    logging.info(f\"Test windows: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,  # Reduced batch size due to longer sequences\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Setup device and model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=2e-5,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    logging.info(\"Starting training...\")\n",
    "    training_stats = train_model(\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=5,\n",
    "        results_dir=results_dir,\n",
    "        gradient_accumulation_steps=4\n",
    "    )\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = [stat['epoch'] for stat in training_stats]\n",
    "    train_losses = [stat['train_loss'] for stat in training_stats]\n",
    "    val_losses = [stat['val_loss'] for stat in training_stats]\n",
    "    \n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(plots_dir, 'training_curves.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    best_model_path = os.path.join(results_dir, 'models', 'best_model.pt')\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        logging.info(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    logging.info(\"\\nEvaluating on validation set...\")\n",
    "    val_metrics = evaluate_model(model, val_dataloader, device, plots_dir, 'validation')\n",
    "    \n",
    "    # Log validation metrics\n",
    "    logging.info(\"\\nValidation Metrics:\")\n",
    "    logging.info(f\"Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    logging.info(f\"Precision: {val_metrics['precision']:.4f}\")\n",
    "    logging.info(f\"Recall: {val_metrics['recall']:.4f}\")\n",
    "    logging.info(f\"F1 Score: {val_metrics['f1']:.4f}\")\n",
    "    logging.info(f\"ROC AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "    logging.info(\"\\nPer-session metrics:\")\n",
    "    logging.info(f\"Mean accuracy: {val_metrics['session_metrics']['mean_accuracy']:.4f}\")\n",
    "    logging.info(f\"Std accuracy: {val_metrics['session_metrics']['std_accuracy']:.4f}\")\n",
    "    \n",
    "    # Save validation metrics\n",
    "    with open(os.path.join(metrics_dir, 'validation_metrics.json'), 'w') as f:\n",
    "        json.dump(val_metrics, f, indent=4)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    logging.info(\"\\nEvaluating on test set...\")\n",
    "    test_metrics = evaluate_model(model, test_dataloader, device, plots_dir, 'test')\n",
    "    \n",
    "    # Log test metrics\n",
    "    logging.info(\"\\nTest Metrics:\")\n",
    "    logging.info(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    logging.info(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "    logging.info(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    logging.info(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
    "    logging.info(f\"ROC AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "    logging.info(\"\\nPer-session metrics:\")\n",
    "    logging.info(f\"Mean accuracy: {test_metrics['session_metrics']['mean_accuracy']:.4f}\")\n",
    "    logging.info(f\"Std accuracy: {test_metrics['session_metrics']['std_accuracy']:.4f}\")\n",
    "    \n",
    "    # Save test metrics\n",
    "    with open(os.path.join(metrics_dir, 'test_metrics.json'), 'w') as f:\n",
    "        json.dump(test_metrics, f, indent=4)\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    model_save_path = os.path.join(models_dir, 'final_model')\n",
    "    tokenizer_save_path = os.path.join(models_dir, 'tokenizer')\n",
    "    \n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(tokenizer_save_path)\n",
    "    \n",
    "    # Save configuration\n",
    "    config = {\n",
    "        'model_name': 'bert-base-multilingual-cased',\n",
    "        'max_length': 256,\n",
    "        'num_labels': 2,\n",
    "        'window_size': 3,\n",
    "        'batch_size': 32,\n",
    "        'gradient_accumulation_steps': 4,\n",
    "        'learning_rate': 2e-5,\n",
    "        'weight_decay': 0.01,\n",
    "        'num_epochs': 5,\n",
    "        'early_stopping_patience': 3,\n",
    "        'train_windows': len(train_dataset),\n",
    "        'val_windows': len(val_dataset),\n",
    "        'test_windows': len(test_dataset)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(models_dir, 'model_config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    logging.info(\"\\nTraining and evaluation completed!\")\n",
    "    logging.info(f\"Model saved to: {model_save_path}\")\n",
    "    logging.info(f\"Tokenizer saved to: {tokenizer_save_path}\")\n",
    "    \n",
    "    return model, tokenizer, {\n",
    "        'train': training_stats,\n",
    "        'validation': val_metrics,\n",
    "        'test': test_metrics\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdd599-db16-40e1-982f-b7bb97013040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "setfit_env",
   "language": "python",
   "name": "setfit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
