{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23c9b53-f684-4434-93ee-a25495971c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2280002/4248719676.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('from IPython.core.display import clear_output');\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "    <script>\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('from IPython.core.display import clear_output');\n",
    "    </script>\n",
    "\"\"\"))\n",
    "\n",
    "import IPython\n",
    "IPython.get_ipython().config.TerminalInteractiveShell.rate_limit_window = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3ee4fd-fee5-4661-9252-6e266afe9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"pred_data_preprocessed.csv\")\n",
    "# Count rows where dicta_answer is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a8ac89-e0aa-471d-b6f3-973b03a00aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df = df.drop(\"position\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21264a54-9591-47e3-a855-ab78061758b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>committee_name</th>\n",
       "      <th>session_id</th>\n",
       "      <th>chairperson</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>conversation</th>\n",
       "      <th>contain_offensive_words</th>\n",
       "      <th>dicta_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>. אני כן אסתום לך את הפה.. .</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>יצחק כהן</td>\n",
       "      <td>. לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>רוחמה אברהם</td>\n",
       "      <td>. אם חברה הולכת להפרטה, אסור לה לפרסם תשקיף..</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>. אני קורא אותך לסדר..</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>אל על</td>\n",
       "      <td>64670</td>\n",
       "      <td>אברהם הירשזון</td>\n",
       "      <td>יצחק כהן</td>\n",
       "      <td>. לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127835</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>קריאות</td>\n",
       "      <td>\\n- - -\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127836</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>גלעד קריב</td>\n",
       "      <td>\\nמין שאינו במינו.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127837</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>\\nההערה הזאת צרמה לי מאוד באוזן על המישור המקצ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127838</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>אלעזר שטרן</td>\n",
       "      <td>\\nאדוני, אני אשמח להגיב לדבר הזה. קודם כול, אנ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127839</th>\n",
       "      <td>ועדת החוקה חוק ומשפט</td>\n",
       "      <td>2225681</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>שמחה רוטמן</td>\n",
       "      <td>\\nמועצה דתית היא לא גוף ספציפי?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127840 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              committee_name  session_id    chairperson    speaker_name  \\\n",
       "0                      אל על       64670  אברהם הירשזון   אברהם הירשזון   \n",
       "1                      אל על       64670  אברהם הירשזון        יצחק כהן   \n",
       "2                      אל על       64670  אברהם הירשזון     רוחמה אברהם   \n",
       "3                      אל על       64670  אברהם הירשזון   אברהם הירשזון   \n",
       "4                      אל על       64670  אברהם הירשזון        יצחק כהן   \n",
       "...                      ...         ...            ...             ...   \n",
       "127835  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן          קריאות   \n",
       "127836  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן       גלעד קריב   \n",
       "127837  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      שמחה רוטמן   \n",
       "127838  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      אלעזר שטרן   \n",
       "127839  ועדת החוקה חוק ומשפט     2225681     שמחה רוטמן      שמחה רוטמן   \n",
       "\n",
       "                                             conversation  \\\n",
       "0                           . אני כן אסתום לך את הפה.. .    \n",
       "1       . לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...   \n",
       "2          . אם חברה הולכת להפרטה, אסור לה לפרסם תשקיף..    \n",
       "3                                 . אני קורא אותך לסדר..    \n",
       "4       . לא, זאת הצעה לסדר. כל הדיון הזה מיותר. אני מ...   \n",
       "...                                                   ...   \n",
       "127835                                          \\n- - -\\n   \n",
       "127836                               \\nמין שאינו במינו.\\n   \n",
       "127837  \\nההערה הזאת צרמה לי מאוד באוזן על המישור המקצ...   \n",
       "127838  \\nאדוני, אני אשמח להגיב לדבר הזה. קודם כול, אנ...   \n",
       "127839                  \\nמועצה דתית היא לא גוף ספציפי?\\n   \n",
       "\n",
       "        contain_offensive_words  dicta_answer  \n",
       "0                             0           0.0  \n",
       "1                             0           0.0  \n",
       "2                             0           0.0  \n",
       "3                             1           1.0  \n",
       "4                             0           0.0  \n",
       "...                         ...           ...  \n",
       "127835                        0           0.0  \n",
       "127836                        0           0.0  \n",
       "127837                        0           0.0  \n",
       "127838                        0           0.0  \n",
       "127839                        0           0.0  \n",
       "\n",
       "[127840 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d036f-9bd3-4516-b92c-1f929db7334c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1337abc-802e-46e6-b8ba-d61e67698d93",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b072343-cb5d-4984-8400-cf580cc69b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 13:57:59,879 - INFO - Starting training process...\n",
      "2025-02-05 13:57:59,879 - INFO - Loaded dataset with 127840 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 13:58:00,914 - INFO - Note: Classifier layer is initialized randomly as expected for fine-tuning\n",
      "2025-02-05 13:58:00,915 - INFO - Class weights: [0.6072466969490051, 2.8310744762420654]\n",
      "2025-02-05 13:58:00,954 - INFO - \n",
      "Dataset splits:\n",
      "2025-02-05 13:58:00,955 - INFO - Training samples: 76704 (60.0%)\n",
      "2025-02-05 13:58:00,955 - INFO - Validation samples: 25568 (20.0%)\n",
      "2025-02-05 13:58:00,956 - INFO - Test samples: 25568 (20.0%)\n",
      "2025-02-05 13:58:00,956 - INFO - \n",
      "Class distribution:\n",
      "2025-02-05 13:58:00,957 - INFO - Training set: [63157 13547]\n",
      "2025-02-05 13:58:00,957 - INFO - Validation set: [21053  4515]\n",
      "2025-02-05 13:58:00,957 - INFO - Test set: [21052  4516]\n",
      "2025-02-05 13:58:00,958 - INFO - Using device: cuda\n",
      "2025-02-05 13:58:01,062 - INFO - \n",
      "Starting training...\n",
      "2025-02-05 13:58:01,063 - INFO - Total training steps: 1800\n",
      "2025-02-05 13:58:01,064 - INFO - Warmup steps: 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 600/600 [02:54<00:00,  3.44it/s, loss=0.1811, lr=2.08e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:02:01,132 - INFO - Epoch 1/3 - Train Loss: 0.4344 - Val Loss: 0.3260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 600/600 [02:08<00:00,  4.67it/s, loss=0.2056, lr=4.17e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:05:15,333 - INFO - Epoch 2/3 - Train Loss: 0.2946 - Val Loss: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 600/600 [02:08<00:00,  4.67it/s, loss=0.1791, lr=4.69e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:08:29,756 - INFO - Epoch 3/3 - Train Loss: 0.2140 - Val Loss: 0.2509\n",
      "2025-02-05 14:08:30,312 - INFO - \n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation set: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s, progress=100.0%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:09:36,761 - INFO - \n",
      "Validation Set Metrics:\n",
      "2025-02-05 14:09:36,763 - INFO - Accuracy: 0.9058\n",
      "2025-02-05 14:09:36,764 - INFO - Precision: 0.7416\n",
      "2025-02-05 14:09:36,764 - INFO - Recall: 0.7163\n",
      "2025-02-05 14:09:36,765 - INFO - F1 Score: 0.7287\n",
      "2025-02-05 14:09:36,766 - INFO - ROC AUC: 0.9175\n",
      "2025-02-05 14:09:36,796 - INFO - \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9396    0.9465    0.9430     21053\n",
      "    Positive     0.7416    0.7163    0.7287      4515\n",
      "\n",
      "    accuracy                         0.9058     25568\n",
      "   macro avg     0.8406    0.8314    0.8359     25568\n",
      "weighted avg     0.9046    0.9058    0.9052     25568\n",
      "\n",
      "2025-02-05 14:09:36,813 - INFO - \n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████| 100/100 [01:05<00:00,  1.53it/s, progress=100.0%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:10:43,116 - INFO - \n",
      "Test Set Metrics:\n",
      "2025-02-05 14:10:43,117 - INFO - Accuracy: 0.9084\n",
      "2025-02-05 14:10:43,117 - INFO - Precision: 0.7477\n",
      "2025-02-05 14:10:43,118 - INFO - Recall: 0.7270\n",
      "2025-02-05 14:10:43,118 - INFO - F1 Score: 0.7372\n",
      "2025-02-05 14:10:43,118 - INFO - ROC AUC: 0.9226\n",
      "2025-02-05 14:10:43,138 - INFO - \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9418    0.9474    0.9446     21052\n",
      "    Positive     0.7477    0.7270    0.7372      4516\n",
      "\n",
      "    accuracy                         0.9084     25568\n",
      "   macro avg     0.8447    0.8372    0.8409     25568\n",
      "weighted avg     0.9075    0.9084    0.9079     25568\n",
      "\n",
      "2025-02-05 14:10:46,168 - INFO - Training and evaluation completed!\n",
      "2025-02-05 14:10:46,168 - INFO - Model saved to: results_baseline/run_20250205_135759/models/final_model\n",
      "2025-02-05 14:10:46,169 - INFO - Tokenizer saved to: results_baseline/run_20250205_135759/models/tokenizer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from torch.amp import autocast, GradScaler\n",
    "import gc\n",
    "import torch.cuda as cuda\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "\n",
    "class DictaDataset(Dataset):\n",
    "    def __init__(self, conversations, labels, tokenizer, max_length=256):\n",
    "        self.conversations = conversations\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conversations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conversation = str(self.conversations[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            conversation,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def calculate_class_weights(y_train):\n",
    "    total_samples = len(y_train)\n",
    "    class_counts = np.bincount(y_train)\n",
    "    class_weights = torch.FloatTensor(total_samples / (len(class_counts) * class_counts))\n",
    "    return class_weights\n",
    "\n",
    "def setup_logging(base_dir='results_baseline'):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    results_dir = os.path.join(base_dir, f'run_{timestamp}')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    log_file = os.path.join(results_dir, 'training.log')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    models_dir = os.path.join(results_dir, 'models')\n",
    "    metrics_dir = os.path.join(results_dir, 'metrics')\n",
    "    \n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "    \n",
    "    return results_dir, plots_dir, models_dir, metrics_dir\n",
    "\n",
    "def save_metrics(metrics, file_path):\n",
    "    metrics_dict = {\n",
    "        'accuracy': float(metrics['accuracy']),\n",
    "        'precision': float(metrics['precision']),\n",
    "        'recall': float(metrics['recall']),\n",
    "        'f1': float(metrics['f1']),\n",
    "        'roc_auc': float(metrics['roc_auc']),\n",
    "        'confusion_matrix': metrics['confusion_matrix'].tolist(),\n",
    "        'classification_report': metrics['classification_report'],\n",
    "        'roc_curve': metrics['roc_curve']\n",
    "    }\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(metrics_dict, f, indent=4)\n",
    "        \n",
    "def evaluate_during_training(model, dataloader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train_model(train_dataloader, val_dataloader, model, optimizer, device, num_epochs=3, results_dir=None, gradient_accumulation_steps=4, patience=3):\n",
    "    model.train()\n",
    "    training_stats = []\n",
    "    scaler = GradScaler('cuda')\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    \n",
    "    # Create scheduler with warmup\n",
    "    num_training_steps = len(train_dataloader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 5  # 20% of training steps for warmup\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps, \n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"Total training steps: {num_training_steps}\")\n",
    "    logging.info(f\"Warmup steps: {num_warmup_steps}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        epoch_stats = {'epoch': epoch + 1, 'batch_losses': []}\n",
    "        \n",
    "        pbar = tqdm(train_dataloader, \n",
    "                   desc=f'Epoch {epoch + 1}/{num_epochs}',\n",
    "                   total=len(train_dataloader),\n",
    "                   dynamic_ncols=True,\n",
    "                   position=0,\n",
    "                   leave=True,\n",
    "                   mininterval=1.0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Clear cache if needed\n",
    "            if batch_idx % 50 == 0:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss / gradient_accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * gradient_accumulation_steps\n",
    "            epoch_stats['batch_losses'].append(loss.item() * gradient_accumulation_steps)\n",
    "            \n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            pbar.set_postfix_str(f'loss={loss.item() * gradient_accumulation_steps:.4f}, lr={current_lr:.2e}', refresh=True)\n",
    "            \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        epoch_stats['average_loss'] = avg_loss\n",
    "        training_stats.append(epoch_stats)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss = evaluate_during_training(model, val_dataloader, device, outputs.loss)\n",
    "        epoch_stats['validation_loss'] = val_loss\n",
    "        \n",
    "        pbar.close()\n",
    "        logging.info(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {avg_loss:.4f} - Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        if results_dir:\n",
    "            stats_file = os.path.join(results_dir, 'metrics', f'epoch_{epoch + 1}_stats.json')\n",
    "            with open(stats_file, 'w') as f:\n",
    "                json.dump(epoch_stats, f, indent=4)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if epoch_stats.get('validation_loss', float('inf')) == early_stopping.best_loss:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(results_dir, 'models', f'checkpoint_best.pt'))\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(f'Early stopping triggered after epoch {epoch + 1}')\n",
    "            break\n",
    "                \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return training_stats\n",
    "    \n",
    "def evaluate_model(model, test_dataloader, device, plots_dir=None, phase='test'):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model to evaluate\n",
    "        test_dataloader: DataLoader containing the evaluation data\n",
    "        device: Device to run the evaluation on (cuda/cpu)\n",
    "        plots_dir: Directory to save plots (optional)\n",
    "        phase: String indicating the evaluation phase ('test', 'validation', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    probabilities = []  # Added to store prediction probabilities\n",
    "    total_batches = len(test_dataloader)\n",
    "    \n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(test_dataloader), \n",
    "        total=total_batches,\n",
    "        desc=f'Evaluating {phase} set',\n",
    "        dynamic_ncols=True,\n",
    "        leave=True\n",
    "    )\n",
    "    \n",
    "    # Evaluation loop\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in progress_bar:\n",
    "            # Move data to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            # Store predictions, probabilities, and labels\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            probabilities.extend(probs[:, 1].cpu().tolist())  # Store probability of positive class\n",
    "            actual_labels.extend(labels.tolist())\n",
    "            \n",
    "            # Update progress bar with completion percentage\n",
    "            progress_bar.set_postfix({\n",
    "                'progress': f'{(batch_idx + 1)/total_batches:.1%}'\n",
    "            })\n",
    "            \n",
    "            # Periodically clear GPU memory\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    precision = precision_score(actual_labels, predictions, average='binary')\n",
    "    recall = recall_score(actual_labels, predictions, average='binary')\n",
    "    f1 = f1_score(actual_labels, predictions, average='binary')\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(actual_labels, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Create and save ROC curve plot\n",
    "    if plots_dir:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {phase.capitalize()} Set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(plots_dir, f'roc_curve_{phase}.png'), \n",
    "                   bbox_inches='tight', \n",
    "                   dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Create and plot confusion matrix\n",
    "        cm = confusion_matrix(actual_labels, predictions)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive']\n",
    "        )\n",
    "        plt.title(f'Confusion Matrix - {phase.capitalize()} Set')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(os.path.join(plots_dir, f'confusion_matrix_{phase}.png'), \n",
    "                   bbox_inches='tight', \n",
    "                   dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # Log results\n",
    "    logging.info(f'\\n{phase.capitalize()} Set Metrics:')\n",
    "    logging.info(f'Accuracy: {accuracy:.4f}')\n",
    "    logging.info(f'Precision: {precision:.4f}')\n",
    "    logging.info(f'Recall: {recall:.4f}')\n",
    "    logging.info(f'F1 Score: {f1:.4f}')\n",
    "    logging.info(f'ROC AUC: {roc_auc:.4f}')\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(\n",
    "        actual_labels, \n",
    "        predictions,\n",
    "        target_names=['Negative', 'Positive'],\n",
    "        digits=4\n",
    "    )\n",
    "    logging.info(f'\\nClassification Report:\\n{class_report}')\n",
    "    \n",
    "    # Prepare and return results dictionary\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': class_report,\n",
    "        'predictions': predictions,\n",
    "        'actual_labels': actual_labels,\n",
    "        'probabilities': probabilities,\n",
    "        'roc_curve': {\n",
    "            'fpr': fpr.tolist(),\n",
    "            'tpr': tpr.tolist()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def predict_single_conversation(conversation, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        conversation,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "    \n",
    "    return preds.item()\n",
    "\n",
    "def main():\n",
    "    # Setup logging and directories\n",
    "    results_dir, plots_dir, models_dir, metrics_dir = setup_logging()\n",
    "    logging.info(\"Starting training process...\")\n",
    "    \n",
    "    # Load your data\n",
    "    logging.info(f\"Loaded dataset with {len(df)} samples\")\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-multilingual-cased',\n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    # Log BERT initialization message\n",
    "    logging.info(\"Note: Classifier layer is initialized randomly as expected for fine-tuning\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df['conversation'].values\n",
    "    y = df['dicta_answer'].values.astype(int)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = calculate_class_weights(y)\n",
    "    logging.info(f\"Class weights: {class_weights.tolist()}\")\n",
    "    \n",
    "    # First split: 80% train+val, 20% test\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: Split the 80% into 75% train, 25% val (60% and 20% of total)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, \n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    # Log splits and class distribution\n",
    "    logging.info(f\"\\nDataset splits:\")\n",
    "    logging.info(f\"Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "    logging.info(f\"Validation samples: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "    logging.info(f\"Test samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "    \n",
    "    logging.info(\"\\nClass distribution:\")\n",
    "    logging.info(f\"Training set: {np.bincount(y_train)}\")\n",
    "    logging.info(f\"Validation set: {np.bincount(y_val)}\")\n",
    "    logging.info(f\"Test set: {np.bincount(y_test)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DictaDataset(X_train, y_train, tokenizer)\n",
    "    val_dataset = DictaDataset(X_val, y_val, tokenizer)\n",
    "    test_dataset = DictaDataset(X_test, y_test, tokenizer)\n",
    "    \n",
    "    # Adjusted batch size and workers for large dataset\n",
    "    batch_size = 128  # Increased batch size\n",
    "    gradient_accumulation_steps = 4  # Increased accumulation steps\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,  # Increased workers\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2  # Add prefetching\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size * 2,  # Larger batch size for validation\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size * 2,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "    \n",
    "    # Setup device and model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Move class weights to device\n",
    "    class_weights = class_weights.to(device)\n",
    "    \n",
    "    # Adjusted learning rate and optimizer parameters\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=5e-5,  # Increased learning rate\n",
    "        weight_decay=0.01,  # Added weight decay\n",
    "        betas=(0.9, 0.999),  # Adjusted momentum parameters\n",
    "    )\n",
    "    \n",
    "    # Train the model with adjusted parameters\n",
    "    logging.info(\"\\nStarting training...\")\n",
    "    training_stats = train_model(\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=3,\n",
    "        results_dir=results_dir,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        patience=3\n",
    "    )\n",
    "    \n",
    "    # Save training curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot([stat['epoch'] for stat in training_stats], \n",
    "             [stat['average_loss'] for stat in training_stats],\n",
    "             label='Training Loss')\n",
    "    plt.plot([stat['epoch'] for stat in training_stats],\n",
    "             [stat['validation_loss'] for stat in training_stats],\n",
    "             label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(plots_dir, 'training_loss.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Load best model from checkpoint\n",
    "    best_model_path = os.path.join(results_dir, 'models', 'checkpoint_best.pt')\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        logging.info(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    logging.info(\"\\nEvaluating on validation set...\")\n",
    "    val_results = evaluate_model(model, val_dataloader, device, plots_dir, 'validation')\n",
    "    save_metrics(val_results, os.path.join(metrics_dir, 'validation_metrics.json'))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    logging.info(\"\\nEvaluating on test set...\")\n",
    "    test_results = evaluate_model(model, test_dataloader, device, plots_dir, 'test')\n",
    "    save_metrics(test_results, os.path.join(metrics_dir, 'test_metrics.json'))\n",
    "    \n",
    "    # Save the final model and tokenizer\n",
    "    model_save_path = os.path.join(models_dir, 'final_model')\n",
    "    tokenizer_save_path = os.path.join(models_dir, 'tokenizer')\n",
    "    \n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(tokenizer_save_path)\n",
    "    \n",
    "    # Save model configuration\n",
    "    config = {\n",
    "        'model_name': 'bert-base-multilingual-cased',\n",
    "        'max_length': 256,\n",
    "        'num_labels': 2,\n",
    "        'batch_size': batch_size,\n",
    "        'gradient_accumulation_steps': gradient_accumulation_steps,\n",
    "        'learning_rate': 5e-5,\n",
    "        'weight_decay': 0.01,\n",
    "        'early_stopping_patience': 3,\n",
    "        'num_epochs': 3,\n",
    "        'train_size': len(X_train),\n",
    "        'val_size': len(X_val),\n",
    "        'test_size': len(X_test),\n",
    "        'class_weights': class_weights.cpu().tolist()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(models_dir, 'model_config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    logging.info(\"Training and evaluation completed!\")\n",
    "    logging.info(f\"Model saved to: {model_save_path}\")\n",
    "    logging.info(f\"Tokenizer saved to: {tokenizer_save_path}\")\n",
    "    \n",
    "    return model, tokenizer, {\n",
    "        'train': training_stats, \n",
    "        'validation': val_results, \n",
    "        'test': test_results\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4af42-e82c-489b-8831-00b78cdea603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "setfit_env",
   "language": "python",
   "name": "setfit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
