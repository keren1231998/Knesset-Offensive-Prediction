{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VPRwRI1nADUZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"dicta-il/dictalm2.0-instruct\", torch_dtype=torch.bfloat16, device_map=device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dicta-il/dictalm2.0-instruct\")"
      ],
      "metadata": {
        "id": "HIad1CjyAtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ResponseData:\n",
        "    \"\"\"Data class for storing response information.\"\"\"\n",
        "    file_name: str\n",
        "    conv: str\n",
        "    response: str"
      ],
      "metadata": {
        "id": "iAf6hc5uASet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationProcessor:\n",
        "    def __init__(self, output_dir):\n",
        "        \"\"\"Initialize the processor with output directory.\"\"\"\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.setup_output_directory()\n",
        "\n",
        "    def setup_output_directory(self):\n",
        "        \"\"\"Create output directory if it doesn't exist.\"\"\"\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def get_surrounding_indices(current_index, df_length, window=3):\n",
        "        \"\"\"Get valid indices around the current index within a specified window.\"\"\"\n",
        "        return range(\n",
        "            max(0, current_index - window),\n",
        "            min(df_length, current_index + window + 1)\n",
        "        )\n",
        "\n",
        "    def process_model_response(response, combine_words) :\n",
        "        \"\"\"Process the model's response and extract relevant information.\"\"\"\n",
        "        response_words = response.strip().split()\n",
        "        filtered_response: List[str] = [\n",
        "            word for word in response_words\n",
        "            if isinstance(word, str) and word not in {\"[INST]\", \"[/INST]\"}\n",
        "        ][len(combine_words):]\n",
        "\n",
        "        # Extract first word for classification\n",
        "        first_word = ''.join(filtered_response[:4])\n",
        "        response_string = ' '.join(filtered_response)\n",
        "\n",
        "        return first_word, response_string\n",
        "\n",
        "    def classify_response(first_word) :\n",
        "        \"\"\"Classify response based on first word.\"\"\"\n",
        "        if \"כן\" in first_word:\n",
        "            return 1\n",
        "        if \"לא\" in first_word:\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    def create_response_data(session_id, conversation, response) :\n",
        "        \"\"\"Create a ResponseData object containing response information.\"\"\"\n",
        "        return ResponseData(\n",
        "            file_name=session_id,\n",
        "            conv=conversation,\n",
        "            response=response\n",
        "        )\n",
        "\n",
        "    def save_results(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        yes_responses: List[ResponseData],\n",
        "        no_responses: List[ResponseData]\n",
        "    ) -> None:\n",
        "        \"\"\"Save all results to CSV files.\"\"\"\n",
        "        yes_df = pd.DataFrame([vars(r) for r in yes_responses]) if yes_responses else pd.DataFrame()\n",
        "        no_df = pd.DataFrame([vars(r) for r in no_responses]) if no_responses else pd.DataFrame()\n",
        "\n",
        "        columns = ['file_name', 'conv', 'response']\n",
        "\n",
        "        if not yes_df.empty:\n",
        "            yes_df.to_csv(\n",
        "                self.output_dir / 'yes_res_call_cut.csv',\n",
        "                columns=columns,\n",
        "                index=False\n",
        "            )\n",
        "\n",
        "        if not no_df.empty:\n",
        "            no_df.to_csv(\n",
        "                self.output_dir / 'no_res_call_cut.csv',\n",
        "                columns=columns,\n",
        "                index=False\n",
        "            )\n",
        "\n",
        "        df.to_csv(\n",
        "            self.output_dir / 'updated_original_df_call_cut.csv',\n",
        "            index=False\n",
        "        )\n",
        "\n",
        "    def process_conversation(\n",
        "        self,\n",
        "        row: pd.Series,\n",
        "        query_model: callable,\n",
        "        example: str\n",
        "    ) -> Tuple[ResponseData, Optional[int]]:\n",
        "        \"\"\"Process a single conversation and get model's response.\"\"\"\n",
        "        conv = row['conversation']\n",
        "\n",
        "        prompt = f'השיחה: \"{conv}\"\\nשאלה: האם המשפט נאמר באופן לא מכבד?\\nתשובה: רק כן או לא.'\n",
        "        asist = \"הבנתי. דוגמה ברורה.\"\n",
        "        combine = f\"{prompt}{asist}{example}\"\n",
        "        combine_words = combine.strip().split()\n",
        "\n",
        "        # Get model response\n",
        "        response = query_model(conv).strip()\n",
        "\n",
        "        first_word, response_string = self.process_model_response(response, combine_words)\n",
        "        classification = self.classify_response(first_word)\n",
        "\n",
        "        response_data = self.create_response_data(\n",
        "            session_id=str(row['session_id']),\n",
        "            conversation=conv,\n",
        "            response=response_string\n",
        "        )\n",
        "\n",
        "        return response_data, classification\n",
        "\n",
        "    def process_responses(\n",
        "        self,\n",
        "        df,\n",
        "        query_model,\n",
        "        example\n",
        "    ):\n",
        "        \"\"\"Main function to process all responses.\"\"\"\n",
        "        yes_responses: List[ResponseData] = []\n",
        "        no_responses: List[ResponseData] = []\n",
        "\n",
        "        relevant_rows = df[\n",
        "            (df['contains_calls_to_order'] == 1) |\n",
        "            (df['contains_cut'] == 1)\n",
        "        ]\n",
        "\n",
        "        for index, row in relevant_rows.iterrows():\n",
        "            session_id = row['session_id']\n",
        "\n",
        "            for idx in self.get_surrounding_indices(index, len(df)):\n",
        "                row_to_check = df.iloc[idx]\n",
        "\n",
        "                if row_to_check['session_id'] == session_id:\n",
        "                    try:\n",
        "                        response_data, classification = self.process_conversation(\n",
        "                            row_to_check, query_model, example\n",
        "                        )\n",
        "\n",
        "                        match classification:\n",
        "                            case 1:\n",
        "                                yes_responses.append(response_data)\n",
        "                            case 0:\n",
        "                                no_responses.append(response_data)\n",
        "                            case _:\n",
        "                                pass\n",
        "\n",
        "                        df.at[index, 'dicta_answer'] = classification\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing row {index}: {str(e)}\")\n",
        "                        df.at[index, 'dicta_answer'] = None\n",
        "\n",
        "        try:\n",
        "            self.save_results(df, yes_responses, no_responses)\n",
        "            print(\"Processing completed. Results saved successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {str(e)}\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "PEfL-sSSEbdA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}